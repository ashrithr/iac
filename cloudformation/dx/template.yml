AWSTemplateFormatVersion: "2010-09-09"
Description: >-
  Creates a Data Exchange pipeline, which performs a full load of the data from
  subscribed dataset, and performs incremental loads based on updated revisions
  of the dataset.
Parameters:
  DxDataSetId:
    AllowedPattern: ^[a-zA-Z0-9]*$
    ConstraintDescription: Malformed DataSet Id.
    Description: Entitled Dataset Id for which the consumption pipeline has to be setup.
    Type: String
  ConsumptionType:
    AllowedValues:
      - FULL
      - INCREMENTAL
    Description: >-
      Type of the consumption pipeline to setup, FULL will perform one-time
      load, where as  INCREMENTAL will perform one-time load and setup a
      monitoring pipeline which will incrementally load data revisions as they
      are published.
    Type: String
    Default: INCREMENTAL
  S3BucketName:
    Type: String
    Description: Bucket used to publish the data to.
  S3CodeBucketName:
    Type: String
    Description: Bucket where Lambda zip files are hosted.

Conditions:
  IsIncrementalLoad: !Equals [!Ref ConsumptionType, INCREMENTAL]
  IsFullLoad: !Equals [!Ref ConsumptionType, FULL]

Resources:
  LambdaIamRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action:
              - sts:AssumeRole
      Path: /
      Policies:
        - PolicyName: CloudWatchLogsPolicy
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: Allow
                Action:
                  - logs:CreateLogGroup
                  - logs:CreateLogStream
                  - logs:PutLogEvents
                Resource: !Sub arn:aws:logs:${AWS::Region}:${AWS::AccountId}:*
        - PolicyName: DataExchangeAccessPolicy
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: Allow
                Action:
                  - dataexchange:GetDataSet
                  - dataexchange:ListDataSet
                  - dataexchange:GetRevision
                  - dataexchange:ListDataSetRevisions
                  - dataexchange:ListRevisionAssets
                  - dataexchange:TagResource
                  - dataexchange:ListTagsForResource
                  - dataexchange:GetAsset
                Resource:
                  - !Sub
                    - arn:aws:dataexchange:${AWS::Region}:${AWS::AccountId}:data-sets/${DxDataSetId}
                    - { DxDataSetId: !Ref DxDataSetId }
                  - !Sub
                    - arn:aws:dataexchange:${AWS::Region}:${AWS::AccountId}:data-sets/${DxDataSetId}/*
                    - { DxDataSetId: !Ref DxDataSetId }
              - Effect: Allow
                Action:
                  - dataexchange:CreateJob
                  - dataexchange:GetJob
                  - dataexchange:StartJob
                  - dataexchange:CancelJob
                  - dataexchange:ListJob
                Resource: "*"
                Condition:
                  StringEqualsIgnoreCase:
                    "dataexchange:JobType": EXPORT_ASSETS_TO_S3
        - PolicyName: S3AccessPolicy
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: Allow
                Action:
                  - s3:GetObject
                Resource:
                  - "*"
                Condition:
                  StringEqualsIgnoreCase:
                    "s3:ExistingObjectTag/aws-data-exchange": "true"
              - Effect: Allow
                Action:
                  - s3:GetObject
                Resource:
                  - arn:aws:s3:::*aws-data-exchange*
              - Effect: Allow
                Action:
                  - s3:PutObject
                  - s3:PutObjectAcl
                Resource:
                  - arn:aws:s3:::*aws-data-exchange*
                  - !Sub
                    - arn:aws:s3:::${S3BucketName}/*
                    - { S3BucketName: !Ref S3BucketName }
              - Effect: Allow
                Action:
                  - "s3:GetBucketLocation"
                Resource:
                  - "*"

  ExportDataSetLambda:
    Type: AWS::Lambda::Function
    Properties:
      Description: Exports specified dataset latest revision to S3 bucket.
      Handler: export_dataset.handler
      Role: !GetAtt LambdaIamRole.Arn
      Runtime: python3.7
      MemorySize: 128
      Timeout: 30
      Code:
        S3Bucket: !Ref S3CodeBucketName
        S3Key: functions/export_dataset.zip

  MonitorExportJob:
    Type: AWS::Lambda::Function
    Properties:
      Description: Monitors the status of an Export Job.
      Handler: monitor_export.handler
      Role: !GetAtt LambdaIamRole.Arn
      Runtime: python3.7
      MemorySize: 128
      Timeout: 30
      Code:
        S3Bucket: !Ref S3CodeBucketName
        S3Key: functions/monitor_export.zip

  StateMachineIamRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - !Sub states.${AWS::Region}.amazonaws.com
            Action:
              - sts:AssumeRole
      Path: /
      Policies:
        - PolicyName: StatesExecutionPolicy
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: Allow
                Action:
                  - lambda:InvokeFunction
                Resource:
                  - !GetAtt ExportDataSetLambda.Arn
                  - !GetAtt MonitorExportJob.Arn

  StateMachine:
    Type: AWS::StepFunctions::StateMachine
    Properties:
      RoleArn: !GetAtt StateMachineIamRole.Arn
      DefinitionString:
        Fn::Sub: |-
          {
            "Comment": "State machine to export data from subscribed data-exchange entitled data-set",
            "StartAt": "Export DataSet",
            "Version": "1.0",
            "States": {
              "Export DataSet": {
                "Type": "Task",
                "Resource": "${ExportDataSetLambda.Arn}",
                "Next": "Wait 1 Minute",
                "Parameters": {
                  "dataset_id": "${DxDataSetId}",
                  "bucket_name": "${S3BucketName}",
                  "prefix": "dx"
                },
                "Retry": [{
                  "ErrorEquals": ["States.TaskFailed"],
                  "IntervalSeconds": 5,
                  "MaxAttempts": 2,
                  "BackoffRate": 5
                }]
              },
              "Wait 1 Minute": {
                "Type": "Wait",
                "Seconds": 60,
                "Next": "Get Export Status"
              },
              "Get Export Status": {
                "Type": "Task",
                "Resource": "${MonitorExportJob.Arn}",
                "Next": "Export Complete?",
                "Retry": [{
                  "ErrorEquals": ["States.TaskFailed"],
                  "IntervalSeconds": 5,
                  "MaxAttempts": 5,
                  "BackoffRate": 2
                }]
              },
              "Export Complete?": {
                "Type": "Choice",
                "Choices": [
                  {
                    "Variable": "$.ExportJob.State",
                    "StringEquals": "COMPLETED",
                    "Next": "Done"
                  },
                  {
                    "Variable": "$.ExportJob.State",
                    "StringEquals": "ERROR",
                    "Next": "Failed"
                  }
                ],
                "Default": "Wait 1 Minute"
              },
              "Done": {
                  "Type": "Pass",
                  "End": true
              },
              "Failed": {
                  "Type": "Pass",
                  "End": true
              }
            }
          }

  DxEventNotification:
    Type: AWS::Events::Rule
    Condition: IsIncrementalLoad
    Properties:
      Description: Monitors entitled dataset for new revisions published
      EventPattern:
        source:
          - aws.dataexchange
        detail-type:
          - Revision Published To Data Set
        resources:
          - !Ref DxDataSetId
      State: ENABLED
      Targets:
        - Arn: !Ref StateMachine
          Id: "StateMachineV1"
          RoleArn: !GetAtt EventsIamRole.Arn

  EventsIamRole:
    Type: AWS::IAM::Role
    Condition: IsIncrementalLoad
    Properties:
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - events.amazonaws.com
            Action:
              - sts:AssumeRole
      Path: /
      Policies:
        - PolicyName: EventsStatesExecutionPolicy
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: Allow
                Action:
                  - states:StartExecution
                Resource: !Ref StateMachine

  LambdaCustomResourceIamRole:
    Type: AWS::IAM::Role
    Condition: IsFullLoad
    Properties:
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action:
              - sts:AssumeRole
      Path: "/"
      Policies:
        - PolicyName: CloudWatchLogsPolicy
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: Allow
                Action:
                  - logs:CreateLogGroup
                  - logs:CreateLogStream
                  - logs:PutLogEvents
                Resource: !Sub arn:aws:logs:${AWS::Region}:${AWS::AccountId}:*
        - PolicyName: StepFunctionsExecutionPolicy
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: Allow
                Action:
                  - states:StartExecution
                Resource: !Ref StateMachine

  ExecuteStateMachineLambda:
    Type: AWS::Lambda::Function
    Condition: IsFullLoad
    Properties:
      Handler: execute_sf.handler
      Role: !GetAtt LambdaCustomResourceIamRole.Arn
      Code:
        S3Bucket: !Ref S3CodeBucketName
        S3Key: functions/execute_sf.zip
      Runtime: python3.7
      Description: Executes a specified State Machine.
      MemorySize: 128
      Timeout: 10

  ExecuteStateMachine:
    Type: Custom::ExecuteStateMachineLambda
    Condition: IsFullLoad
    Properties:
      ServiceToken: !GetAtt ExecuteStateMachineLambda.Arn
      SF_ARN: !Ref StateMachine

Outputs:
  ExportedDataSetId:
    Value: !Ref DxDataSetId
  StateMachineArn:
    Value: !Ref StateMachine
